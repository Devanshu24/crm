{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f0520a-a034-4530-adad-780ea6a3a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crm import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1cdb7b9-5081-47b9-bf71-9b8db78938f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1d40082ef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "random.seed(20)\n",
    "torch.manual_seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc8d8bf-213c-4be2-8b8e-589fc3c1a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        dill.dump(obj, outp, dill.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as inp:\n",
    "        return dill.load(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2775a557-166f-47db-90b5-65671fb583fa",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20815390-4f5f-4050-8d3b-6b7089f35327",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train  = load_object(\"data/sample5/X_train.dill\"), load_object(\"data/sample5/y_train.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946369cf-0068-4e69-b2d7-08cdef420403",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test  = load_object(\"data/sample5/X_test.dill\"), load_object(\"data/sample5/y_test.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f4656b-7c7a-4776-a726-0bd5f5079b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list = load_object(\"data/sample5/adj_list.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fc2250-67cf-4ab8-bc0d-e25a9bfc737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = list(zip(X_train, y_train))\n",
    "random.shuffle(c)\n",
    "X_train, y_train = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe3208-a9e8-4eea-be0b-4da2e849d13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87bebdb0-f1c6-4425-9d5f-af194d74c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = load_object(\"data/inputs.dill\")\n",
    "outputs = load_object(\"data/outputs.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17551e7b-de87-4482-8713-e9f8d6793741",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset_inputs = torch.rand(700, 23)\n",
    "for i in range(700):\n",
    "    torch_dataset_inputs[i] = torch.tensor(list(inputs[i].values())[:23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa8aac9-7aa0-46d7-95cd-04a34e745e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_dataset_outputs = torch.stack([outputs[i] for i in range(700)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23856f1a-2594-42d6-90c7-6de57208c147",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list = load_object(\"data/adj_list.dill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e69f97-99e1-4d62-90d3-30543c1c648d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f6a7119-37cb-4708-851b-cac555bed0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = len(adj_list)\n",
    "n = Network(num_neurons, adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fe6335-6927-4dde-9cf5-22214a5bc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.set_neuron_activation(977, lambda x : x, lambda x : 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a56c9167-9771-44e3-b045-6e44aed0d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.set_neuron_activation(978, lambda x : x, lambda x : 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d43800c-e163-4e82-a579-dc9679b32a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.weights = load_object(\"weights_train_test_split__seed_20.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76be6068-f4b6-481b-a1f6-f6e3896d4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.weights = load_object(\"data/sample5/weights_99_33.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2c9f05d-6d9e-4f58-9e4c-647252200c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, outputs, test_size=1/7, random_state=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "891f8d8a-5c05-4073-9114-2f307cd95cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638b8982c2c74220bd82dfd73b25703d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181782cc925f4d6c9b78e182c0e61250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee70d85ed05c48ae8a40165acfc015e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7809e31641c438386f3d874d344d602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(n.parameters(), lr=0.001)\n",
    "losses = []\n",
    "num_epochs = 3\n",
    "for e in trange(num_epochs):\n",
    "    c = list(zip(X_train, y_train))\n",
    "    random.shuffle(c)\n",
    "    X_train, y_train = zip(*c)\n",
    "    for i in trange(len(X_train)):\n",
    "        f_mapper = X_train[i]\n",
    "        out = n.forward(f_mapper).reshape(1, -1)\n",
    "        loss = F.cross_entropy(out, y_train[i].reshape(1))\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        n.reset()\n",
    "# print(n.weights)\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2887fe39-6e4b-4daf-9c17-313894f2b7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb852fd29c024373942b17d835915889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "train_correct = 0\n",
    "for i in trange(len(X_train)):\n",
    "    f_mapper = X_train[i]\n",
    "    out = n.forward(f_mapper).reshape(1, -1)\n",
    "    train_correct += 1 if torch.argmax(out)==y_train[i] else 0\n",
    "    n.reset()\n",
    "print(\"Train Accuracy: \", train_correct/len(X_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec221573-b14e-40b3-b67c-03c08151d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bc80dd1a0c4b55900864a7fb89026f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  99.66666666666667\n"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "for i in trange(len(X_test)):\n",
    "    f_mapper = X_test[i]\n",
    "    out = n.forward(f_mapper).reshape(1, -1)\n",
    "    test_correct += 1 if torch.argmax(out)==y_test[i] else 0\n",
    "    n.reset()\n",
    "print(\"Test Accuracy: \", test_correct/len(X_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b511c5cc-ead1-4d78-a696-2ffe84c520b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0435905a11a4b25841413158da613d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  99.57142857142857\n"
     ]
    }
   ],
   "source": [
    "#M2\n",
    "train_correct = 0\n",
    "for i in trange(len(X_train)):\n",
    "    f_mapper = X_train[i]\n",
    "    out = n.forward(f_mapper).reshape(1, -1)\n",
    "    train_correct += 1 if torch.argmax(out)==y_train[i] else 0\n",
    "    n.reset()\n",
    "print(\"Train Accuracy: \", train_correct/len(X_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb2e42e-71c2-49d9-8d13-1a86ddbda388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43743ec4d734672a404656f7a441008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  99.33333333333333\n"
     ]
    }
   ],
   "source": [
    "test_correct = 0\n",
    "for i in trange(len(X_test)):\n",
    "    f_mapper = X_test[i]\n",
    "    out = n.forward(f_mapper).reshape(1, -1)\n",
    "    test_correct += 1 if torch.argmax(out)==y_test[i] else 0\n",
    "    n.reset()\n",
    "print(\"Test Accuracy: \", test_correct/len(X_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ad34423-c797-4504-94fc-fe9f14156594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 299)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_correct, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c56f2d97-b7c3-44ac-a038-b5e38f6b0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(n.weights, \"data/sample5/weights_100.dill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd386a9-1815-4481-a6c7-d29ea8dffaa4",
   "metadata": {},
   "source": [
    "# LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "474ab7d0-7054-4748-8995-e7f2386fa1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/dmitrysarov/LRP_decomposition/blob/master/notebooks/LRP_notebook_mnist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "32fb88fe-f34d-4639-9c6e-ec1374c4dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_presence(network, n_ids, percentile):\n",
    "    max_layer = max([nn.layer for nn in network.neurons])\n",
    "    min_layer = min([nn.layer for nn in network.neurons])\n",
    "    N_IDs = [i for i in range(network.num_neurons) if network.neurons[i].layer == (max_layer-1)]\n",
    "    RELs = [network.neurons[i].relevance for i in N_IDs]\n",
    "    SORTED_N_IDs = [x for _,x in sorted(zip(RELs,N_IDs))]\n",
    "    SORTED_N_IDs.reverse()\n",
    "    for i in n_ids:\n",
    "        if (SORTED_N_IDs.index(i))<percentile*(len(SORTED_N_IDs)):\n",
    "            return (1, SORTED_N_IDs)\n",
    "    return (0, SORTED_N_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45ea6e-33fd-4798-8ed4-c85c86acd0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b15bd299-139c-458e-9fd2-ba7b7714f735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_layer = max([nn.layer for nn in n.neurons])\n",
    "max_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4276eb68-8ac5-4845-845d-7c931a00cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {}\n",
    "for nn in n.neurons:\n",
    "    if nn.layer in layers:\n",
    "        layers[nn.layer].append(nn.n_id)\n",
    "    else:\n",
    "        layers[nn.layer]=[nn.n_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1f077450-12f1-4284-bc1e-53fc1ef97171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([117.2262], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.reset()\n",
    "n.forward(X_train[0])\n",
    "n.neurons[1283].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b2e22b8c-80d4-4e06-9d0a-a14d0258f707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba98fdd2b9b642889f7123f79ba52fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train Set\n",
    "counts = 0\n",
    "total = 0\n",
    "sorted_nids = None\n",
    "with trange(len(y_train)) as t:\n",
    "    for i in t:\n",
    "        if y_train[i]==1:\n",
    "            n.reset()\n",
    "            n.forward(X_train[i])\n",
    "            n.lrp(100., 1283)\n",
    "            inc, sorted_nids=check_presence(network= n, n_ids = [756, 711, 633], percentile=0.01) #(Not including 27)\n",
    "            counts+=inc\n",
    "            total+=1\n",
    "        t.set_postfix({\"Counts\": counts, \"Total\": total, \"Ratio\": counts/total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d64d9829-6167-48de-abec-89e22658b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% 600/600 [2:20:47<00:00, 16.50s/it, Counts=302, Total=351, Ratio=0.86] 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "24556ec3-3529-4926-857d-930d5a596a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99595b6df6d341958d10474bf49d148f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Set\n",
    "counts = 0\n",
    "total = 0\n",
    "sorted_nids = None\n",
    "with trange(len(y_test)) as t:\n",
    "    for i in t:\n",
    "        if y_test[i]==1:\n",
    "            n.reset()\n",
    "            n.forward(X_test[i])\n",
    "            n.lrp(100., 1283)\n",
    "            inc, sorted_nids=check_presence(network= n, n_ids = [756, 711, 633], percentile=0.01) #(Not including 27)\n",
    "            counts+=inc\n",
    "            total+=1\n",
    "        t.set_postfix({\"Counts\": counts, \"Total\": total, \"Ratio\": counts/total if total else None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0ebb2542-8f07-4285-878c-5623f5f6c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% 100/100 [21:56<00:00, 17.30s/it, Counts=46, Total=54, Ratio=0.852] 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5750690b-ebda-4dad-9750-a8226107e858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4409a51615f64609baefb48e6147b23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Set\n",
    "counts = 0\n",
    "total = 0\n",
    "sorted_nids = None\n",
    "with trange(len(y_test)) as t:\n",
    "    for i in t:\n",
    "        if y_test[i]==1:\n",
    "            n.reset()\n",
    "            n.forward(X_test[i])\n",
    "            n.lrp(100., 1283)\n",
    "            inc, sorted_nids=check_presence(network= n, n_ids = [756, 711, 633], percentile=0.03) #(Not including 27)\n",
    "            counts+=inc\n",
    "            total+=1\n",
    "        t.set_postfix({\"Counts\": counts, \"Total\": total, \"Ratio\": counts/total if total else None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "375beb68-3ed6-4f2d-8f74-de319656ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% 100/100 [21:37<00:00, 17.27s/it, Counts=46, Total=54, Ratio=0.852] 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "549e795b-80b6-4151-aea7-c842d33f9e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100.0, 1283, 3),\n",
       " (38.31831359863281, 22, 0),\n",
       " (20.276439666748047, 20, 0),\n",
       " (16.41777801513672, 23, 1),\n",
       " (15.62519645690918, 25, 1),\n",
       " (14.337860107421875, 21, 0),\n",
       " (8.297679901123047, 19, 0),\n",
       " (7.704973220825195, 97, 1),\n",
       " (6.702298641204834, 14, 0),\n",
       " (5.8988213539123535, 34, 1),\n",
       " (5.820578575134277, 15, 0),\n",
       " (5.541997909545898, 12, 0),\n",
       " (2.9191713333129883, 712, 2),\n",
       " (2.3127784729003906, 29, 1),\n",
       " (2.2477352619171143, 756, 2)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rel = -1\n",
    "idx = -1\n",
    "rels = []\n",
    "for n_id in range(1284):\n",
    "    if True:#1283 in n.neurons[n_id].successor_neurons or 1282 in n.neurons[n_id].successor_neurons:\n",
    "        try:\n",
    "            rels.append((n.neurons[n_id].relevance.item(), n_id, n.neurons[n_id].layer))\n",
    "        except:\n",
    "            pass\n",
    "rels.sort(reverse=True)\n",
    "rels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "567d0244-7c9f-4196-bfe2-662c2eee35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrainSet: Top1%         Top3%\n",
    "# TestSet: Top1%       Top3%\n",
    "# Want to see: hasCar(X,Y), short(Y), closed(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a950c12-abb8-4bb3-acb1-9537b5c0ee65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08329967776584318"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/931*77.552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d65b9c3-f991-42d6-9668-fca4779e76c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.24"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8063d8cb-39bd-4544-86c5-776ced44c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6337], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[711].relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "03d96d24-8199-4030-8969-ee557a4a4eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[240][0][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f7427287-eeaa-486d-bce6-7bb3c17d4e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1), tensor(-1), tensor(2), tensor(-1), tensor(1., grad_fn=<MulBackward0>), tensor(2., grad_fn=<MulBackward0>)]\n",
      "[tensor(0., grad_fn=<AddBackward0>), tensor(0., grad_fn=<AddBackward0>), tensor(40., grad_fn=<AddBackward0>), tensor(-30., grad_fn=<AddBackward0>), 0, tensor(10.)]\n"
     ]
    }
   ],
   "source": [
    "demo = Network(6, [[4], [4], [5], [5], [], []])\n",
    "demo.weights = {\n",
    "        (0, 4): torch.tensor(6.0, requires_grad=True),\n",
    "        (1, 4): torch.tensor(5.0, requires_grad=True),\n",
    "        (2, 5): torch.tensor(4.0, requires_grad=True),\n",
    "        (3, 5): torch.tensor(6.0, requires_grad=True),\n",
    "}\n",
    "demo.forward({0: 1, 1: -1, 2: 2, 3: -1, 4: 1, 5: 1})\n",
    "print([demo.neurons[i].value for i in range(len(demo.neurons))])\n",
    "demo.lrp(torch.tensor(10.0), 5)\n",
    "print([demo.neurons[i].relevance for i in range(len(demo.neurons))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff297201-9053-460c-b1dc-35dfc520ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_layers = {}\n",
    "for nn in demo.neurons:\n",
    "    if nn.layer in d_layers:\n",
    "        d_layers[nn.layer].append(nn.n_id)\n",
    "    else:\n",
    "        d_layers[nn.layer]=[nn.n_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2313350d-00d7-4df2-bb04-6c56af28eeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3], 1: [4, 5]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3af9500f-44fe-43dd-9966-e9ccc8c5353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([demo.neurons[n_id].relevance for n_id in d_layers[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a778671-583a-45c9-aa68-4e89bfbfe04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100.0, 1283, 3),\n",
       " (50.09611511230469, 22, 0),\n",
       " (28.143735885620117, 23, 1),\n",
       " (25.122875213623047, 21, 0),\n",
       " (11.22695541381836, 3, 0),\n",
       " (10.006945610046387, 18, 0),\n",
       " (7.728886127471924, 298, 1),\n",
       " (4.784719467163086, 25, 1),\n",
       " (3.5847561359405518, 712, 2),\n",
       " (3.547109842300415, 19, 0),\n",
       " (3.1040234565734863, 713, 2),\n",
       " (2.742990493774414, 757, 2),\n",
       " (2.4108364582061768, 632, 2),\n",
       " (2.3875539302825928, 859, 2),\n",
       " (2.3309028148651123, 29, 1)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rel = -1\n",
    "idx = -1\n",
    "rels = []\n",
    "for n_id in range(1284):\n",
    "    if True:#1283 in n.neurons[n_id].successor_neurons or 1282 in n.neurons[n_id].successor_neurons:\n",
    "        try:\n",
    "            rels.append((n.neurons[n_id].relevance.item(), n_id, n.neurons[n_id].layer))\n",
    "        except:\n",
    "            pass\n",
    "rels.sort(reverse=True)\n",
    "rels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f3291e10-ce22-45a2-a665-3b8b91911ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0725861ea8d04a2ea35cb17cf89c2983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(n.parameters(), lr=0.001)\n",
    "losses = []\n",
    "correct = 0\n",
    "for i in trange(len(dataset)):\n",
    "    f_mapper = dataset[i][0]\n",
    "    f_mapper[1282]=1\n",
    "    f_mapper[1283]=1\n",
    "    out = n.forward(f_mapper).reshape(1, -1)\n",
    "    correct += 1 if torch.argmax(out)==dataset[i][1] else 0\n",
    "    n.reset()\n",
    "print(correct/700*100)\n",
    "# print(n.weights)\n",
    "print(losses)\n",
    "# plt.plot(losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d31e7aaa-3228-4109-b196-755cad0062ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(n, \"network_100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b91bd42-5228-40a6-ac34-6b9e68639f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_network_n = load_object(\"network_100.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d1168fb-b455-4a5f-a000-e2aeb12103ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_network_n.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adbe0096-07f1-4e06-86d3-684e8af55501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32298b0f2f14e9588c2661262abbfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'loaded_network_n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18615/1428735106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1282\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mf_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1283\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_network_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloaded_network_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded_network_n' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(n.parameters(), lr=0.001)\n",
    "losses = []\n",
    "correct = 0\n",
    "for i in trange(len(dataset)):\n",
    "    f_mapper = dataset[i][0]\n",
    "    f_mapper[1282]=1\n",
    "    f_mapper[1283]=1\n",
    "    out = loaded_network_n.forward(f_mapper).reshape(1, -1)\n",
    "    correct += 1 if torch.argmax(out)==dataset[i][1] else 0\n",
    "    loaded_network_n.reset()\n",
    "print(correct/700*100)\n",
    "# print(n.weights)\n",
    "print(losses)\n",
    "# plt.plot(losses)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40a46b0-1d07-4a69-bbc2-6249657714f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3115)\n",
      "1 tensor(6.2305)\n",
      "2 tensor(93.4579)\n",
      "3 tensor(100.)\n"
     ]
    }
   ],
   "source": [
    "n = Network(4, [[3], [3], [3], []])\n",
    "n.weights = {\n",
    "    (0,3): torch.tensor(1.),\n",
    "    (1, 3):torch.tensor(2.),\n",
    "    (2, 3):torch.tensor(3.),\n",
    "}\n",
    "n.forward({0:10, 1: 100, 2: 1000, 3: 1})\n",
    "n.lrp(torch.tensor(100.), 3)\n",
    "for gg in n.neurons:\n",
    "    print(gg.n_id, gg.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aecb08c-adc8-4a6b-93b7-0877f091a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.3115)\n",
      "1 tensor(6.2305)\n",
      "2 tensor(93.4579)\n",
      "3 tensor(100.)\n",
      "4 0\n"
     ]
    }
   ],
   "source": [
    "n = Network(5, [[3,4], [3,4], [3,4], [], []])\n",
    "n.weights = {\n",
    "    (0,3): torch.tensor(1.),\n",
    "    (1, 3):torch.tensor(2.),\n",
    "    (2, 3):torch.tensor(3.),\n",
    "    (0, 4): torch.tensor(3.),\n",
    "    (1, 4):torch.tensor(2.),\n",
    "    (2, 4):torch.tensor(1.),\n",
    "}\n",
    "n.forward({0:10, 1: 100, 2: 1000, 3: 1, 4:1})\n",
    "n.lrp(torch.tensor(100.), 3)\n",
    "for gg in n.neurons:\n",
    "    print(gg.n_id, gg.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4946adc-432a-4c12-8c0c-876683d73540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([n.neurons[i].layer for i in range(n.num_neurons)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d51a075-8998-47cf-9398-1d73dc5d934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_output_neurons = []\n",
    "orig_output_neurons_check= []\n",
    "for gg in n.neurons:\n",
    "    if gg.successor_neurons == [977, 978]:\n",
    "        orig_output_neurons.append(gg.n_id)\n",
    "    if gg.layer == 2:\n",
    "        orig_output_neurons_check.append(gg.n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc9c0f0a-4fc3-43a0-805d-869960bdf4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f989ba9d-b532-467c-88c1-b73bc9c2e379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 979)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_output_neurons), n.num_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eeff464-5390-445d-8a30-d1721c8e3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_f_vals = [i for i in range(n.num_neurons) if X_train[0][i]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0238046a-2451-44bc-9813-2e1593047fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero_f_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27355b1a-ea9f-4aeb-a5ba-b102410e834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = 0\n",
    "for i in range(num_neurons):\n",
    "    if i not in zero_f_vals:\n",
    "        oo+=n.neurons[i].relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11249da4-4bbe-450c-8e01-67bfd1079794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[90.4348],\n",
       "         [83.1681]], grad_fn=<StackBackward0>),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.reset()\n",
    "n.forward(X_train[1]), y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d6560e-bd4b-4655-aa52-7ef96776996c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4b45b3f-c482-4d61-89b4-affadbc07106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([83.1681], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[978].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d17081f2-119c-462b-b95d-b063050405e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c581e06c0494ca4a7019664f55649a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_l = {i:0 for i in range(n.num_neurons)}\n",
    "for i in trange((30)):\n",
    "    if y_test[i]:\n",
    "        n.reset()\n",
    "        n.forward(X_test[i])\n",
    "        n.lrp(torch.tensor(100.), 978)\n",
    "        l = ([(n.neurons[i].relevance, i) for i in orig_output_neurons])\n",
    "        for rel, idx in l:\n",
    "            main_l[idx]+=rel\n",
    "# main_l.sort(reverse=True)\n",
    "# main_l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "539b9adf-aaed-4e84-9c2a-d4f22c57555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = []\n",
    "for k, v in (main_l.items()):\n",
    "    rels.append((v, k+1))\n",
    "rels.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c684c84-851a-4c3d-b0bf-7a64cb8fde0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 165)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "real = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i]:\n",
    "        real+=1\n",
    "        if X_test[i][326]:\n",
    "            c+=1\n",
    "c, real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66dd470c-d3e9-4568-8a7a-ae01d0a1bf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[977, 978]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[326].predeccesor_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b07ffc75-89b7-4f09-a26a-25fda182adf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([382.3938], grad_fn=<AddBackward0>), 327),\n",
       " (tensor([80.3215], grad_fn=<AddBackward0>), 935),\n",
       " (tensor([72.6319], grad_fn=<AddBackward0>), 510),\n",
       " (tensor([69.2016], grad_fn=<AddBackward0>), 372),\n",
       " (tensor([66.7294], grad_fn=<AddBackward0>), 641),\n",
       " (tensor([50.2880], grad_fn=<AddBackward0>), 703),\n",
       " (tensor([47.1415], grad_fn=<AddBackward0>), 791),\n",
       " (tensor([41.5360], grad_fn=<AddBackward0>), 412),\n",
       " (tensor([41.0481], grad_fn=<AddBackward0>), 879),\n",
       " (tensor([35.8847], grad_fn=<AddBackward0>), 371)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6cc7f7f-e1dd-4150-8130-41ef00d21c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1237, 931)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(orig_output_neurons)), len(set(orig_output_neurons_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c0d3ef4-9f9f-4919-b142-81fd490bedd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1282, 1283], 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[24].successor_neurons, n.neurons[24].layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a777974-bcfe-420d-93b4-f95da82b6e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(orig_output_neurons) - set(orig_output_neurons_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "884e4bb8-e984-4617-a6af-57145f0c9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(n.weights, \"weights_100_trained_on_600_samples.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d9b26ea-5070-427d-9d3c-5c621a003df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = load_object(\"weights_100_trained_on_600_samples.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6763e877-f807-41c0-8de1-20ff296a9cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.weights = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66876e77-4168-4a1c-807f-65ac69c0a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://math.stackexchange.com/questions/945871/derivative-of-softmax-loss-function\n",
    "import torch\n",
    "for f in f_mapper_global:\n",
    "    f[1282]=1\n",
    "    f[1283]=1\n",
    "    n.reset()\n",
    "    o = n.forward(f)\n",
    "    if o[0]!=torch.tensor([0.]):\n",
    "        print(o)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "51a51f0d-b1be-4142-8e8a-5b731e051325",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Sequential(torch.nn.Linear(10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dde0ccb1-4e64-4709-bd07-99e878aa016a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2583, -0.2650, -0.1380,  0.2627, -0.0312,  0.1305, -0.2825,  0.2821,\n",
       "        -0.1505, -0.1986,  0.1177, -0.0656, -0.2120,  0.2727,  0.2055,  0.2070,\n",
       "         0.0710,  0.1732,  0.0441,  0.2178,  0.0877,  0.0890, -0.2641,  0.1323,\n",
       "         0.2862,  0.1050, -0.0550,  0.0561,  0.1339,  0.1444, -0.1224,  0.0247,\n",
       "        -0.2285, -0.1712,  0.2991,  0.2760,  0.3068, -0.2236,  0.1844,  0.2605,\n",
       "         0.1401, -0.1417,  0.0496, -0.2446,  0.2426,  0.2560,  0.0176, -0.0214,\n",
       "         0.0734, -0.2629, -0.1454, -0.0164, -0.2263, -0.1252,  0.2839,  0.1112,\n",
       "        -0.1526, -0.2420,  0.1288, -0.2328, -0.1631, -0.2980, -0.2495,  0.0282,\n",
       "         0.2589,  0.1794, -0.2060,  0.0578, -0.1831, -0.0485,  0.1794,  0.1493,\n",
       "        -0.2882, -0.2283,  0.1230, -0.0346,  0.0167, -0.0178,  0.0618,  0.3064,\n",
       "         0.2408, -0.1345,  0.1730,  0.0623,  0.2448,  0.2489,  0.2486, -0.2769,\n",
       "         0.0622, -0.0840, -0.0709,  0.1767, -0.0693,  0.1541,  0.2729,  0.1055,\n",
       "         0.1617, -0.2165, -0.3010, -0.0245], requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.parameters())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61b821d8-007a-4a6d-89d6-b598c94fa8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_neurons = []\n",
    "for neuron in n.neurons:\n",
    "    if len(neuron.predeccesor_neurons)==0:\n",
    "        input_neurons.append(neuron.n_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "53de15b5-a045-4c30-b41c-640e68181bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0331c56b-f622-47ac-8d26-28ce34e0909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(inp_dim, 64), nn.ReLU(), nn.Linear(64, 32),nn.ReLU(), nn.Linear(32, 2))\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "cf112802-8124-4684-985f-b89b373430c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(23, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d020a3aa-c6d6-4d05-a4db-846b20d5bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "552d7c03-e469-4497-80d7-606e56c9de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 600\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    out = mlp(torch_dataset_inputs)\n",
    "    loss = F.cross_entropy(out, torch_dataset_outputs)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "33532ceb-ce7e-4c12-8aa2-7f4de084f09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21631726622581482"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f8f8c7a4-837b-4104-8bc8-127eff50f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_out = mlp(torch_dataset_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5ec891e2-95fe-484a-90c0-a0370d75a9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(613)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(trained_out, dim=1) == torch_dataset_outputs).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3be3ac9a-aaaf-481e-853e-5c5bd1c12fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757142857142857"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "613/700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a81c25ac-bec5-4c1e-9812-7d313da1168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.script(mlp).save(\"torch_model_87_57.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f30ef623-dffc-455e-b5dd-1b65a0816e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=23, out_features=64, bias=True)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.mlp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ec341350-ee34-4ef0-a6b8-7cb03652d9c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Cannot choose target column with output shape torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-198-1d9b3e234d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerLRP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Attribution size matches input size: 3x3x32x32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_dataset_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/captum/attr/_core/layer/layer_lrp.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, target, additional_forward_args, return_convergence_delta, attribute_to_layer_input, verbose)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# 1. Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             output = self._compute_output_and_change_weights(\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/captum/attr/_core/lrp.py\u001b[0m in \u001b[0;36m_compute_output_and_change_weights\u001b[0;34m(self, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_weight_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     )\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_verify_select_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_verify_select_column\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    511\u001b[0m     assert (\n\u001b[1;32m    512\u001b[0m         \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     ), \"Cannot choose target column with output shape %r.\" % (output.shape,)\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Cannot choose target column with output shape torch.Size([2])."
     ]
    }
   ],
   "source": [
    "from captum.attr import LayerLRP\n",
    "lrp = LayerLRP(mlp, mlp.mlp[0])\n",
    "# Attribution size matches input size: 3x3x32x32\n",
    "attribution = lrp.attribute(torch_dataset_inputs[0], target=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "28bfcb9d-c973-409b-b9ea-dd87ab1583b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_key(dictionary, n=0):\n",
    "    if n < 0:\n",
    "        n += len(dictionary)\n",
    "    for i, key in enumerate(dictionary.keys()):\n",
    "        if i == n:\n",
    "            return key\n",
    "    raise IndexError(\"dictionary index out of range\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "25d4fbfa-3dc6-4331-9484-ab855b33023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = get_nth_key(n.weights, 132)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5171f3a-2d5a-4f7e-8167-d1a95b5ba9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(n.weights)):\n",
    "    a, b = get_nth_key(n.weights, i)\n",
    "    if a in input_neurons:\n",
    "        print((a, b), n.weights[(a, b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "479ea420-46d5-4344-a57b-13dd7d4c9aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1282, 1283]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.output_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a9071067-84b4-4a16-82c8-fe7b28506314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65.8915], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[1283].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7db7cd87-8e10-44cf-b3e5-bb893ffa5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a3452823-f9a2-498d-a083-3257c1f4fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5f7efc35-2d12-48fc-a2ce-8a9947f9dc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[60.5862],\n",
       "        [65.8915]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.forward(dataset[24][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7c65629a-3283-4510-a2bb-e9b740190b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fad90b1-e1b8-4958-bc9f-01d5d8f2f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(700):\n",
    "    if dataset[i][1]==torch.tensor(0):\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fd844-da97-4c50-b7c5-1bbc8003b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.lrp(torch.tensor(100), 1283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3ee91356-804b-4778-8a55-878165519d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.3627], grad_fn=<AddBackward0>),\n",
       " tensor([1.0818], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[30].relevance, n.neurons[26].relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf990be4-5eb8-4a77-9a83-50ee1f8d64ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.5326], grad_fn=<AddBackward0>) 25\n"
     ]
    }
   ],
   "source": [
    "val = -1\n",
    "idx= -1 \n",
    "for i in range(len(n.neurons)):\n",
    "    if val < n.neurons[i].relevance and i!=1283 and len(n.neurons[i].predeccesor_neurons)>0:\n",
    "        val = n.neurons[i].relevance\n",
    "        idx=i\n",
    "print(val, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3acfb3a9-50b1-48c1-a172-e4aa13380f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([2.5776], grad_fn=<AddBackward0>)\n",
      "1 tensor([6.5669], grad_fn=<AddBackward0>)\n",
      "2 tensor([4.8625], grad_fn=<AddBackward0>)\n",
      "3 tensor([7.3552], grad_fn=<AddBackward0>)\n",
      "4 tensor([1.6697], grad_fn=<AddBackward0>)\n",
      "5 tensor([4.3789], grad_fn=<AddBackward0>)\n",
      "6 tensor([2.8425], grad_fn=<AddBackward0>)\n",
      "7 tensor([3.3122], grad_fn=<AddBackward0>)\n",
      "8 tensor([3.0336], grad_fn=<AddBackward0>)\n",
      "9 tensor([2.3799], grad_fn=<AddBackward0>)\n",
      "10 tensor([2.4768], grad_fn=<AddBackward0>)\n",
      "11 tensor([8.8196], grad_fn=<AddBackward0>)\n",
      "12 tensor([5.6021], grad_fn=<AddBackward0>)\n",
      "13 tensor([3.6882], grad_fn=<AddBackward0>)\n",
      "14 tensor([6.9309], grad_fn=<AddBackward0>)\n",
      "15 tensor([4.5565], grad_fn=<AddBackward0>)\n",
      "16 tensor([4.7223], grad_fn=<AddBackward0>)\n",
      "17 tensor([5.4705], grad_fn=<AddBackward0>)\n",
      "18 tensor([5.1625], grad_fn=<AddBackward0>)\n",
      "19 tensor([5.7853], grad_fn=<AddBackward0>)\n",
      "20 tensor([7.8064], grad_fn=<AddBackward0>)\n",
      "21 tensor([0.], grad_fn=<AddBackward0>)\n",
      "22 tensor([0.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for neuron in n.neurons:\n",
    "    if len(neuron.predeccesor_neurons)==0:\n",
    "        print(neuron.n_id, neuron.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8389d39-4ad2-4270-841f-d0b7d5164723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 22]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[23].predeccesor_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85a1d36a-ff9d-4bb4-8fb9-df6aeab03857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[60.5862],\n",
       "        [65.8915]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.reset()\n",
    "n.forward(dataset[24][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ea131013-e2d7-45d9-8259-28445df3c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.reset()\n",
    "n.forward(dataset[24][0])\n",
    "n.lrp(torch.tensor(100.), 1283)\n",
    "N_ID = [i for i in range(1284)]\n",
    "REL_VALS = [n.neurons[n_id].relevance for n_id in N_ID]\n",
    "S = [x for _,x in sorted(zip(REL_VALS,N_ID))]\n",
    "S.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1f0a4ad7-317d-4136-887e-8bf10e7a0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(n, x):\n",
    "    n.reset()\n",
    "    out = n.forward(x)\n",
    "    return torch.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9744726-dbd1-4368-9225-fe6902a4e67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(n, dataset[24][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c71e975-a61b-4fe6-b87a-5fc570c34759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_lrp(n, dataset_id):\n",
    "    n.reset()\n",
    "    x = dataset[dataset_id][0]\n",
    "    n.forward(x)\n",
    "    \n",
    "    if dataset[dataset_id][1]:\n",
    "        n.lrp(torch.tensor(100.), 1283)\n",
    "        # print(\"here\")\n",
    "    else:\n",
    "        n.lrp(torch.tensor(100.), 1282)\n",
    "        # print(\"there\")\n",
    "    \n",
    "    N_ID = [i for i in range(23)]\n",
    "    REL_VALS = [n.neurons[n_id].relevance for n_id in N_ID]\n",
    "    S = [x for _,x in sorted(zip(REL_VALS,N_ID))]\n",
    "    \n",
    "    R = []\n",
    "    found = False\n",
    "    \n",
    "    if dataset[dataset_id][1]:\n",
    "        S.append(1283)\n",
    "        # print(\"here\")\n",
    "    else:\n",
    "        S.append(1282)\n",
    "        # n.lrp(torch.tensor(100.), 1282)\n",
    "        # print(\"there\")\n",
    "    \n",
    "    S.reverse()\n",
    "    while (len(S)!=0 and found==False):\n",
    "        R.append(S[0])\n",
    "        x_dash = {i: 1 if i in R else 0 for i in range(1284)}\n",
    "        for n_id in range(1284):\n",
    "            if len(n.neurons[n_id].predeccesor_neurons)==0:\n",
    "                continue\n",
    "            if x_dash[n.neurons[n_id].predeccesor_neurons[0]] and x_dash[n.neurons[n_id].predeccesor_neurons[1]]:\n",
    "                x_dash[n_id]=1\n",
    "        out_dash = predict(n, x_dash)\n",
    "        out = predict(n, x)\n",
    "        # print(out, out_dash)\n",
    "        if out_dash == out:\n",
    "            found = True\n",
    "        else:\n",
    "            found = False\n",
    "        S = S[1:]\n",
    "    \n",
    "    print(R)\n",
    "    # x_real = {i: 1 if i in R else 0 for i in range(1285)}\n",
    "    # print(x_real)\n",
    "    # n.reset()\n",
    "#     out = n.forward(x_real)\n",
    "#     if dataset[dataset_id][1]:\n",
    "#         n.lrp(torch.tensor(100.), 1283)\n",
    "#     else:\n",
    "#         n.lrp(torch.tensor(100.), 1282)\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ba76048-790e-4d9f-b4b1-2c812be8ac43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97, 180]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[403].predeccesor_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3bba467-6371-43bd-a1fe-5adb91f1ebfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55.7140],\n",
       "        [61.7247]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.reset()\n",
    "n.forward(dataset[458][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c9e05e0-005d-4199-ad5d-faa9b6a0b771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([61.7247], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.neurons[1283].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5a7cf-5949-4cab-89d5-c933625b87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(f(35),[type=simple,def=(train(_131143):-has_car(_131143,_131149),open_car(_131149))]).\n",
    "\n",
    "func(f(19),[type=simple,def=(train(_131143):-has_car(_131143,_131149),open_car(_131149))]).\n",
    "func(f(23),[type=simple,def=(train(_131143):-has_car(_131143,_131146))]).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b13f5c-33ec-45f3-b052-92aac6cac31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "func(f(24),[type=simple,def=(train(_131143):-has_car(_131143,_131149),short(_131149))]).\n",
    "\n",
    "func(f(23),[type=simple,def=(train(_131143):-has_car(_131143,_131146))]).\n",
    "func(f(22),[type=simple,def=(train(_131143):-has_car(_131143,_131149),short(_131149))])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e99db9d3-ede7-4b92-8b80-9f7e0b0d4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.lrp(torch.tensor(100.), 1283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5160a641-cfa1-4916-bcc3-c9a080b33577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.], grad_fn=<AddBackward0>)\n",
      "1 tensor([0.], grad_fn=<AddBackward0>)\n",
      "2 tensor([0.], grad_fn=<AddBackward0>)\n",
      "3 tensor([0.], grad_fn=<AddBackward0>)\n",
      "4 tensor([0.], grad_fn=<AddBackward0>)\n",
      "5 tensor([0.], grad_fn=<AddBackward0>)\n",
      "6 tensor([0.], grad_fn=<AddBackward0>)\n",
      "7 tensor([0.], grad_fn=<AddBackward0>)\n",
      "8 tensor([0.], grad_fn=<AddBackward0>)\n",
      "9 tensor([0.], grad_fn=<AddBackward0>)\n",
      "10 tensor([0.], grad_fn=<AddBackward0>)\n",
      "11 tensor([0.], grad_fn=<AddBackward0>)\n",
      "12 tensor([0.], grad_fn=<AddBackward0>)\n",
      "13 tensor([0.], grad_fn=<AddBackward0>)\n",
      "14 tensor([0.], grad_fn=<AddBackward0>)\n",
      "15 tensor([6.4179], grad_fn=<AddBackward0>)\n",
      "16 tensor([0.], grad_fn=<AddBackward0>)\n",
      "17 tensor([0.], grad_fn=<AddBackward0>)\n",
      "18 tensor([0.], grad_fn=<AddBackward0>)\n",
      "19 tensor([11.4728], grad_fn=<AddBackward0>)\n",
      "20 tensor([23.7107], grad_fn=<AddBackward0>)\n",
      "21 tensor([18.0010], grad_fn=<AddBackward0>)\n",
      "22 tensor([40.3976], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for neuron in n.neurons:\n",
    "    if len(neuron.predeccesor_neurons)==0:\n",
    "        print(neuron.n_id, neuron.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d6dc1b8c-12d5-494c-8427-9bef6711b6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[169.3681],\n",
       "        [176.5970]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data = {i: 0 for i in range(1284)}\n",
    "for i in range(23):\n",
    "    temp_data[i]=0\n",
    "temp_data[22]=1\n",
    "for n_id in range(1284):\n",
    "    if len(n.neurons[n_id].predeccesor_neurons)==0:\n",
    "        continue\n",
    "    if temp_data[n.neurons[n_id].predeccesor_neurons[0]] or temp_data[n.neurons[n_id].predeccesor_neurons[1]]:\n",
    "        temp_data[n_id]=1\n",
    "n.reset()\n",
    "n.forward(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "584880e9-3b7a-4ba2-81f1-bcee9ae785c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1283, 22, 20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1283, 22, 20]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_lrp(n, 458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65808efa-8a55-4f4b-9a13-15d9070a130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[458][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55987400-2b69-43f7-977b-f373d4dd8668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1282, 1283]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.output_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "642b1202-fe6a-470d-b62b-b55f4304d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.reset()\n",
    "out = n.forward({i: 0 for i in range(1285)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0659aceb-ffe4-4b7b-8881-28f76f4a0963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6b88705f-7392-43ea-9835-6fad6256b5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([0.], grad_fn=<AddBackward0>)\n",
      "1 tensor([0.], grad_fn=<AddBackward0>)\n",
      "2 tensor([0.], grad_fn=<AddBackward0>)\n",
      "3 tensor([0.], grad_fn=<AddBackward0>)\n",
      "4 tensor([0.], grad_fn=<AddBackward0>)\n",
      "5 tensor([0.], grad_fn=<AddBackward0>)\n",
      "6 tensor([0.], grad_fn=<AddBackward0>)\n",
      "7 tensor([0.], grad_fn=<AddBackward0>)\n",
      "8 tensor([0.], grad_fn=<AddBackward0>)\n",
      "9 tensor([0.], grad_fn=<AddBackward0>)\n",
      "10 tensor([0.], grad_fn=<AddBackward0>)\n",
      "11 tensor([0.], grad_fn=<AddBackward0>)\n",
      "12 tensor([0.], grad_fn=<AddBackward0>)\n",
      "13 tensor([0.], grad_fn=<AddBackward0>)\n",
      "14 tensor([0.], grad_fn=<AddBackward0>)\n",
      "15 tensor([0.], grad_fn=<AddBackward0>)\n",
      "16 tensor([0.], grad_fn=<AddBackward0>)\n",
      "17 tensor([0.], grad_fn=<AddBackward0>)\n",
      "18 tensor([0.], grad_fn=<AddBackward0>)\n",
      "19 tensor([0.], grad_fn=<AddBackward0>)\n",
      "20 tensor([0.], grad_fn=<AddBackward0>)\n",
      "21 tensor([0.], grad_fn=<AddBackward0>)\n",
      "22 tensor([0.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for neuron in n.neurons:\n",
    "    if len(neuron.predeccesor_neurons)==0:\n",
    "        print(neuron.n_id, neuron.relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0c1204fe-d997-4b0c-9b4e-22958a3638f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if dataset[42][1]:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b336c326-7219-4a92-a60f-b8caffe5bb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[118.6430],\n",
       "        [124.5332]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.reset()\n",
    "n.forward(dataset[42][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91273127-32c4-4be8-98b3-51233fc08b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.lrp(torch.tensor(100.), 1283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "328b081f-294a-4316-8adb-088d01509518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2477], grad_fn=<AddBackward0>) 712\n"
     ]
    }
   ],
   "source": [
    "max_rel = -1\n",
    "idx = -1\n",
    "for n_id in range(1284):\n",
    "    if 1283 in n.neurons[n_id].successor_neurons or 1282 in n.neurons[n_id].successor_neurons:\n",
    "        if n.neurons[n_id].relevance > max_rel:\n",
    "            max_rel=n.neurons[n_id].relevance\n",
    "            idx=n_id\n",
    "print(max_rel, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2657bc3-173e-41a3-8ecb-97685033fc75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb58c41bbb521262f95c6d9ac0a5f393619bf1006f16a13252f81f5c637c534f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
